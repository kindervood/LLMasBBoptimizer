# -*- coding: utf-8 -*-
"""Experiments (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FGbyxAX8bcr9wObu4WUNxq2RvfLOyJta

#Развертывание LLM

В командной строке пропишите:

curl -fsSL https://ollama.com/install.sh | sh

ollama serve &

ollama run gemma3:1b
"""

!pip install colab-xterm

# Commented out IPython magic to ensure Python compatibility.
# %load_ext colabxterm
# %xterm

!pip install ollama

"""##Пример обращения к llm:"""

import ollama
model = 'gemma3:1b'
prompt = 'Are u a reasoning model?'
response = ollama.chat(model=model, messages=[{'role':'user', 'content':prompt}])
print(response['message'])

"""#Эксперименты с плохими функциями"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import time

# Функция создания prompt-а для LLM
def create_prompt(num_sol, df):
    meta_prompt_start = '''You will help me minimize a function with multiple variables.
                          I have some (w) pairs and the function values at those points.
                          The pairs are arranged in descending order based on their function values,
                          where lower values are better.\n\n'''
    solutions = ''
    if num_sol > len(df):
        num_sol = len(df)
    for i in range(num_sol):
        w_vector = df.w.iloc[-num_sol + i]
        weight_str = ', '.join([f'{num:.3f}' for num in w_vector])
        solutions += f'''input: w=[{weight_str}] value:{df.loss.iloc[-num_sol + i]:.3f}'''
    return meta_prompt_start + solutions

# Функция, реализующая оптимизацию с помощью LLM.
# Сохраняем также каждое сгенерированное значение (вектор) в x_list для дальнейшей визуализации сходимости.
def run_optimization(function, dim, num_solutions, max_iter=100):
    # Начальное случайное решение
    w = np.random.uniform(-5, 5, dim)
    print(w)
    loss = function(w)

    # Создаем DataFrame для хранения истории: столбец "w" хранит список, представляющий вектор
    df = pd.DataFrame({'loss': [loss], 'w': [w.tolist()]})
    loss_list = [loss]
    x_list = [w.copy()]  # сохраняем вектор решения в каждом шаге

    for i in range(max_iter):
        system_prompt = create_prompt(num_solutions, df)

        prompt = f'''Give me a new w({dim} dimensional) that is different from all pairs above for at least 1e-6 for each cooordinate,
                and has a function value lower than any of the above.
                The output MUST CONTAIN ONLY a pair of numerical values for w
                in format "w = [w_1, w_2, ..., w_{dim}]" and NOTHING ELSE. Do not write code and repeat weights'''
        response = ollama.chat(model=model, messages=[{"role": "system", "content": system_prompt},{'role':'user', 'content':prompt}])
        output = response['message']['content']

        # Разбор вывода LLM
        try:
            print(output)
            if '[' in output and ']' in output:
              output = output[-30:]
              f_output = output[output.index('[')+1:output.index(']')]
            new_w = np.array([float(x.strip()) for x in f_output.split(',')])
        except Exception as e:
            print("Error parsing output:", output)
            continue

        new_loss = function(new_w)

        # Добавляем новое решение в DataFrame и историю потерь.
        new_row = {'loss': new_loss, 'w': [new_w.tolist()]}  # оборачиваем список, чтобы сохранить в одной ячейке
        df = pd.concat([df, pd.DataFrame(new_row, index=[0])], ignore_index=True)
        loss_list.append(new_loss)
        x_list.append(new_w.copy())

        # Сортируем DataFrame по значению loss (убывание – худшие решения в начале, лучшие в конце)
        df.sort_values(by='loss', ascending=False, inplace=True)
        if i % 100 == 0:
          print(f'Step {i}: Value={new_loss}')


    return df, loss_list, x_list

# Функция для построения графиков сходимости:
# 1) по норме разницы между значением функции и оптимальным значением (f* = 0)
# 2) по норме разницы между аргументом и оптимальным аргументом (оптимум – вектор 0)
def plot_results(loss_list, x_list, function_name):
    iterations = np.arange(len(loss_list))

    f_gap = [abs(loss) for loss in loss_list]
    # Оптимум для аргумента – вектор нулей
    x_gap = [np.linalg.norm(x) for x in x_list]

    fig, axs = plt.subplots(1, 2, figsize=(14, 6))

    axs[0].plot(iterations, f_gap, marker='o', label='|f(x)-f*|')
    axs[0].set_yscale('log')
    axs[0].set_xlabel('Iteration')
    axs[0].set_ylabel('Function gap')
    axs[0].set_title(f'Convergence by function value gap ({function_name})')
    axs[0].grid(True, which="both", linestyle=":")
    axs[0].legend()

    axs[1].plot(iterations, x_gap, marker='o', label='||x-x*||')
    axs[1].set_yscale('log')
    axs[1].set_xlabel('Iteration')
    axs[1].set_ylabel('Argument gap')
    axs[1].set_title('Convergence by argument gap')
    axs[1].grid(True, which="both", linestyle=":")
    axs[1].legend()

    plt.tight_layout()
    plt.show()

df, loss_list, x_list = run_optimization(rastrigin, dim=3, num_solutions=50, max_iter=100)

plot_results(loss_list, x_list, "Rastrigin Function")

df, loss_list, x_list = run_optimization(rastrigin, dim=3, num_solutions=50, max_iter=200)

plot_results(loss_list, x_list, "Rastrigin Function")

import numpy as np

def ackley(w, a=20, b=0.2, c=2*np.pi):
    """Ackley function"""
    n = len(w)
    sum_sq = sum(xi**2 for xi in w)
    sum_cos = sum(np.cos(c*xi) for xi in w)
    return -a * np.exp(-b * np.sqrt(sum_sq / n)) \
           - np.exp(sum_cos / n) + a + np.e

def griewank(w):
    """Griewank function"""
    part1 = sum(xi**2 for xi in w) / 4000
    part2 = np.prod([np.cos(xi / np.sqrt(i + 1)) for i, xi in enumerate(w)])
    return part1 - part2 + 1

def levy(w):
    """Levy function"""
    w_ = [1 + (xi - 1) / 4 for xi in w]
    term1 = np.sin(np.pi * w_[0])**2
    term2 = sum(
        (w_[i] - 1)**2 * (1 + 10 * np.sin(np.pi * w_[i] + 1)**2)
        for i in range(len(w) - 1)
    )
    term3 = (w_[-1] - 1)**2 * (1 + np.sin(2 * np.pi * w_[-1])**2)
    return term1 + term2 + term3

def sphere(w):
    """Sphere function (sum of squares)"""
    return sum(xi**2 for xi in w)

def rosenbrock(w):
    """Rosenbrock function"""
    return sum(
        100 * (w[i+1] - w[i]**2)**2 + (w[i] - 1)**2
        for i in range(len(w) - 1)
    )

def rastrigin(w):
    """Rastrigin function"""
    return 10 * len(w) + sum([(xi**2 - 10 * np.cos(2 * np.pi * xi)) for xi in w])

functions = [ackley, griewank, levy, sphere, rosenbrock, rastrigin]

for function in functions:
  dim = 3
  num_solutions = 50
  max_iter = 100
  df, loss_list, x_list = run_optimization(function, dim=dim, num_solutions=num_solutions, max_iter=max_iter)
  plot_results(loss_list, x_list, function.__doc__)

NUM_EXP = 5
function = rastrigin
dim = 3
num_solutions = 50
max_iter = 200
avg_loss = []
avg_x = []
for N in range(NUM_EXP):
  # у всех функций минимум в 0 равный 0, для чистоты эксперимента генерирую сдвиг аргумента
  shift = np.random.uniform(-5, 5, dim)
  print(shift)
  df, loss_list, x_list = run_optimization(lambda x: function(x+shift), dim=dim, num_solutions=num_solutions, max_iter=max_iter)
  avg_loss.append(loss_list)
  avg_x.append(x_list)
  plot_results(loss_list, x_list+shift, function.__doc__ + f'{N + 1} experiment')

avg_loss = avg_loss.mean(axis=0)
avg_x = avg_x.mean(axis=0)
plot_results(avg_loss, avg_x+shift, function.__doc__)

avg_loss

plot_results(avg_loss, avg_x+shift, function.__doc__)

"""#Эксперименты с хорошими функциями большой размерности

"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

x = np.arange(0, 6, 0.5) # create true values for x
y = 3*x + np.random.randint(-1, 2, 12) # create true values for y + noise

# initialize random weights for the linear function y = w*x + b - equation for our line
# during optimization, we will change the weights w, b, calculate the resulting "y" and compare them with the true values "y"
w = np.random.uniform(-5, 5)
b = np.random.uniform(-5, 5)

def loss_calc(y, w, x, b):
    return ((y - w*x + b)**2).mean() # mean squared error loss function

loss = loss_calc(y, w, x, b)

d = {'loss': [loss], 'w': [w], 'b': [b]}
loss_list = [loss] # collect all losses for plotting at the end

df = pd.DataFrame(data=d) # dataset to store all the proposed weights (w, b) and calculated loss
df.sort_values(by=['loss'], ascending=False, inplace=True)


def is_number_isdigit(s): # function for parsing str response from LLM
    n1 = s[0].replace('.','',1).replace('-','',1).strip().isdigit()
    n2 = s[1].replace('.','',1).replace('-','',1).strip().isdigit()
    return n1 * n2

def check_last_solutions(loss_list, last_nums): # function that stops optimization when the last "last_nums" values of the loss function < 1
    if len(loss_list) >= last_nums:
        last = loss_list[-last_nums:]
        return all(num < 1 for num in last)

def create_prompt(num_sol): # create prompt
    meta_prompt_start = f'''Now you will help me minimize a function with two input variables w, b. I have some (w, b) pairs and the function values at those points.
The pairs are arranged in descending order based on their function values, where lower values are better.\n\n'''

    solutions = ''
    if num_sol > len(df.loss):
        num_sol = len(df.loss)

    for i in range(num_sol):
        solutions += f'''input:\nw={df.w.iloc[-num_sol + i]:.3f}, b={df.b.iloc[-num_sol + i]:.3f}\nvalue:\n{df.loss.iloc[-num_sol + i]:.3f}\n\n'''

    meta_prompt_end = f'''Give me a new (w, b) pair that is different from all pairs above, and has a function value lower than
any of the above. Do not write code. The output must end with a pair [w, b], where w and b are numerical values.

w, b ='''

    return meta_prompt_start + solutions + meta_prompt_end

num_solutions = 10 # number of observations to feed into the prompt

for i in range(500):

    text = create_prompt(num_solutions)

    response = ollama.chat(model=model, messages=[{"role": "system", "content": text},{'role':'user', 'content':prompt}])
    response = response['message']['content']


    if "\n" in response:
        response = response.split("\n")[0].strip()

    if "," in response:
        numbers = response.split(',')

    if is_number_isdigit(numbers):
        w, b = float(numbers[0].strip()), float(numbers[1].strip())
        loss = loss_calc(y, w, x, b)
        loss_list.append(loss)
        new_row = {'loss': loss, 'w': w, 'b': b}
        new_row_df = pd.DataFrame(new_row, index=[0])
        df = pd.concat([df, new_row_df], ignore_index=True)
        df.sort_values(by='loss', ascending=False, inplace=True)

    if i % 20 == 0:
        print(f'{w=} {b=} loss={loss:.3f}')

    if check_last_solutions(loss_list, 3):
        break

fig, ax = plt.subplots()
print(f'number of step = {len(loss_list)}')
# ax.plot(loss_list);
ax.plot([x for x in loss_list if x < 700]);